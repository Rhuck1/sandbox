{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagonal(mat):\n",
    "    '''Given a matrix encoded as a 2 dimensional python list (i.e. a list of\n",
    "    uniform length lists), returns a list containing all the values along the\n",
    "    diagonal starting at the index 0, 0. (Assumes that the matrix is nonempty.)\n",
    "\n",
    "    FOR FULL POINTS DON'T USE IMPORTS AND LOOP THE LESSER OF THE NUMBER OF ROWS AND COLUMNS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat: list of lists\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> mat = [[1, 2], [3, 4], [5, 6]]\n",
    "    >>> get_diagonal(mat)\n",
    "    [1, 4]\n",
    "    '''\n",
    "    return [mat[i][i] for i in range(min(len(mat), len(mat[0])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "get_diagonal(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def same_proportion_minority_class(X, y, test_size=0.2):\n",
    "    '''Performs a train-test split on the X and y data, returning:\n",
    "    X_train, X_test, y_train, y_test in that order.\n",
    "    default split should be 80%-20%\n",
    "    However, the target y is categorical (0 and 1) and there is a large\n",
    "    class imbalance.  So train-test split is specified such that the\n",
    "    proportion of the minority class is preserved between the train and\n",
    "    test sets.\n",
    "    You may use imports for this question.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X, y: NumPy Array, NumPy Array\n",
    "    Returns\n",
    "    -------\n",
    "    X_train, X_test, y_train, y_test:\n",
    "        NumPy Array, NumPy Array, NumPy Array, NumPy Array\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a SQL query that returns the number of markets that do not have 'Farmers Market' in its name AND which are located in states with a population greater than 20,000,000 in 2010.\n",
    "\n",
    "If you would like to test your query locally, database files and instructions are available here.\n",
    "'''\n",
    "\n",
    "\n",
    "def filtered_market_count():\n",
    "    '''\n",
    "    INPUT: NONE\n",
    "    OUTPUT: STRING\n",
    "    Return a SQL statement which gives the number of markets that do not have \n",
    "    'Farmers Market' in its name. Please only include markets in states with a \n",
    "    large population in 2010 (greater than 20,000,000).\n",
    "    '''\n",
    "\n",
    "    return '''SELECT COUNT(*)\n",
    "                FROM farmersmarkets AS fm\n",
    "                JOIN statepopulations AS sp\n",
    "                ON sp.state = fm.State\n",
    "                WHERE sp.pop2010 > 20000000 AND\n",
    "                      fm.MarketName NOT LIKE '%Farmers Market%';\n",
    "           '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a SQL query that returns a table containing each state, number of people per farmers market (using the population number from 2010). \n",
    "If a state does not appear in the farmersmarket table, it should still appear in your result with a count of 0.\n",
    "'''\n",
    "\n",
    "\n",
    "def market_density_per_state():\n",
    "    '''\n",
    "    INPUT: NONE\n",
    "    OUTPUT: STRING\n",
    "    Return a SQL statement which gives a table containing each state, number\n",
    "    of people per farmers market (using the population number from 2010).\n",
    "    If a state does not appear in the farmersmarket table, it should still\n",
    "    appear in your result with a count of 0.\n",
    "    '''\n",
    "\n",
    "    return '''\n",
    "             SELECT p.state, COALESCE(p.pop2010 / m.cnt, 0)\n",
    "               FROM statepopulations p\n",
    "               LEFT OUTER JOIN (\n",
    "                 SELECT state, COUNT(1) AS cnt\n",
    "                   FROM farmersmarkets \n",
    "                   GROUP BY state) m \n",
    "                 ON p.state=m.state\n",
    "            ;\n",
    "           '''\n",
    "\n",
    "# Alternate queries for edification\n",
    "#     return '''\n",
    "#            -- Replace COALESCE from previous example with CASE WHEN\n",
    "#            SELECT p.State, \n",
    "#                 CASE \n",
    "#                   WHEN m.cnt IS NULL THEN 0\n",
    "#                   ELSE pop2010 / m.cnt \n",
    "#                 END\n",
    "#               FROM statepopulations p\n",
    "#                 LEFT OUTER JOIN (\n",
    "#                   SELECT state, COUNT(1) AS cnt\n",
    "#                     FROM farmersmarkets\n",
    "#                     GROUP BY state) m \n",
    "#                   ON p.State = m.state\n",
    "#             ;\n",
    "#            '''\n",
    "# \n",
    "#     return '''\n",
    "#            -- Remove subquery from previous example\n",
    "#            -- Flip join order\n",
    "#            SELECT p.State, \n",
    "#                CASE \n",
    "#                  WHEN COUNT(FMID) = 0 THEN 0 \n",
    "#                  ELSE pop2010 / COUNT(FMID) \n",
    "#                END\n",
    "#              FROM farmersmarkets m\n",
    "#                RIGHT OUTER JOIN statepopulations p \n",
    "#                  ON p.State = m.state\n",
    "#              GROUP BY p.State, pop2010\n",
    "#            ;\n",
    "#            '''\n",
    "# \n",
    "#     return '''\n",
    "#            -- Replace CASE WHEN from previous example with COALESCE\n",
    "#            -- Use FULL JOIN instead of LEFT JOIN or RIGHT JOIN\n",
    "#            SELECT p.State, COALESCE(pop2010 / NULLIF(COUNT(FMID), 0), 0) \n",
    "#              FROM farmersmarkets m\n",
    "#                FULL JOIN statepopulations p \n",
    "#                  ON p.State = m.state\n",
    "#              GROUP BY p.State, pop2010\n",
    "#            ;\n",
    "#            '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 70-year-old woman visits a doctor complaining of abdominal pain. The doctor knows that there are only three potential causes of abdominal pain given the patient's medical history and that they cannot co-occur.  They are presented below with their prevalence:\n",
    "\n",
    "* partial small-bowel obstruction - 30%  \n",
    "* peptic ulcer disease - 30%  \n",
    "* diverticulitis - 40%  \n",
    "\n",
    "Abdominal pain is a symptom in 70% of partial small-bowel obstructions, 30% of peptic ulcer disease cases, and 50% of diverticulitis cases.  \n",
    "\n",
    "What is the most likely condition the patient has? What is the calculated likelihood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BO = {Bowel Obstruction}, PUD = {Peptic Ulcer Disease}, D = {Diverticulitis}`\n",
    "\n",
    "    Calculate their probabilities.\n",
    "\n",
    "    `P(BO) = 0.30, P(PUD) = 0.30 , P(D) = 0.40`\n",
    "\n",
    "    `AP = {Abdominal Pain}`\n",
    "\n",
    "    Find the probability that a patient having one of the three \n",
    "    conditions will have abdominal pain\n",
    "\n",
    "    `P(AP|BO) = 0.70, P(AP|PUD) = 0.30, P(AP|D) = 0.50.`\n",
    "\n",
    "    `P(AP) = P(AP|BO) * P(BO) + P(AP|PUD) * P(PUD) + P(AP|D) * P(D)`\n",
    "\n",
    "        = 0.70 * 0.30 + 0.30 * 0.30 + 0.50 * 0.40\n",
    "        \n",
    "        = 0.50\n",
    "\n",
    "    Use Bayes' theorem\n",
    "\n",
    "    `P(BO|AP) = P(AP|BO) * P(BO) / P(AP) `\n",
    "            `= (0.70 * .30) / 0.50 = 0.42`\n",
    "    `P(PUD|AP) = P(AP|PUD) * P(PUD) / P(AP) `\n",
    "            `= (0.30 * .30) / 0.50 = 0.18`\n",
    "    `P(D|AP) = P(AP|D) * P(D) / P(AP) `\n",
    "            `= (0.50 * .40) / 0.50 = 0.40`\n",
    "\n",
    "    The patient is likeliest to have a partial small-bowel obstruction, \n",
    "    with a calculated likelihood of 42%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a corpus made up of the following four documents:  \n",
    "\n",
    "Doc 1: Dogs like dogs more than cats.  \n",
    "Doc 2: The dog chased the bicycle.  \n",
    "Doc 3: The cat rode in the bicycle basket.  \n",
    "Doc 4: I have a fast bicycle.\n",
    "\n",
    "We assume that we are lowercasing everything, stemming, and removing stop words and punctuation.\n",
    "\n",
    "These are the features you should have:\n",
    "\n",
    "dog, like, cat, chase, bicycle, ride, basket, fast\n",
    "\n",
    "Use the unnormalized versions of TF and DF that you learned in class to answer the following questions.\n",
    "\n",
    "* What is the term frequency vector for Document 1 (2 pts)?  \n",
    "\n",
    "* What is the document frequency vector for all the words in the corpus (1 pt)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    doc1_term_frequency = [2, 1, 1, 0, 0, 0, 0, 0]  \n",
    "\n",
    "    doc_frequency = [2, 1, 2, 1, 3, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PCA utilizing eigen-decomposition, explain:\n",
    "\n",
    "a) How the principal components are calculated. (2 pts.)\n",
    "\n",
    "b) How to calculate the proportion of total variance explained by one principal component. (1 pt.) (THIS IS THE ONE THAT I MISSED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a) \n",
    "    \n",
    "    Principal components can be calculated using eigen-decomposition or with SVD.\n",
    "    In the case of eigen-decomposition, the feature covariance/correlation matrix is decomposed into \n",
    "    a matrix of eigenvectors and a list of corresponding eigenvalues. The eigenvectors are the principal components.\n",
    "    Eigenvalues indicate the magnitude of each of the eigenvectors, that is, the portion of 'variance' associated with each eigenvector.\n",
    "\n",
    "    b) \n",
    "    \n",
    "    The variance explained by one component is its eigenvalue divided by the sum\n",
    "    of all the eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THESE ARE THE ONES THAT I GOT CORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Describe the process of choosing the best k in k-Means. (2 pts.)\n",
    "\n",
    "b) List 2 ways of computing the distance between clusters in hierarchical clustering. (1 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a)\n",
    "    Utilize the elbow method which plots differing values of cost with a changing k, utilized in conjunction with Within Cluster Sum of Squared error as WSS diminishes an elbow appears on the plot.\n",
    "\n",
    "    b)\n",
    "    Single linkage: shortest distance between clusters\n",
    "    Complete linkage: longest distance between clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix below shows nutritional values for 5 food items.\n",
    "    \n",
    "                -------------------------------------------------------\n",
    "                | Apple | Banana | Bell Pepper | Blue Crab | Broccoli |\n",
    "    --------------------------------------------------------------------\n",
    "    |Calories    |  130  |   110  |      25     |    100    |     45   |\n",
    "    --------------------------------------------------------------------\n",
    "    |Sodium      |    0  |     0  |      40     |    330    |     80   |\n",
    "    --------------------------------------------------------------------\n",
    "    |Potassium   |  260  |   450  |     220     |    300    |    460   |\n",
    "    --------------------------------------------------------------------\n",
    "    |Carbohydrate|   34  |    30  |       6     |      0    |      8   |\n",
    "    --------------------------------------------------------------------\n",
    "    |Vitamin A   |    2  |     2  |       4     |      0    |      6   |   \n",
    "    --------------------------------------------------------------------\n",
    "    |Vitamin C   |    8  |    15  |     190     |      4    |    220   |  \n",
    "    --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn's NMF class in its decomposition library:\n",
    "\n",
    "a) Provide code that would factorize this matrix into W and H matrices. Consider the number of latent topics whether to change them from the default value. Paste the code into the space below. Some starter code is provided (2 pts).\n",
    "\n",
    "Note: Your submission will be recorded when you hit 'Run Tests' and will be evaluated by hand. All submissions that run without error pass the AUTOMATED test. Regardless, feel free to update your code and hit 'Run Tests' again to save a new version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobbyhuck/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 100 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nut_vals=np.array([[130, 110,  25, 100,  45],\n",
    "                   [  0,   0,  40, 330,  80],\n",
    "                   [260, 450, 220, 300, 460],\n",
    "                   [ 34,  30,   6,   0,   8],\n",
    "                   [  2,   2,   4,   0,   6],\n",
    "                   [  8,  15, 190,   4, 220]])\n",
    "\n",
    "# your code below\n",
    "\n",
    "nmf = NMF(n_components=5, max_iter=100)\n",
    "\n",
    "W = nmf.fit_transform(nut_vals)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe why you used the number of latent topics you did in your NMF. (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Because I intuitively broke them up into the following categories: minerals, energy, fruits, vegetables, and meat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the NMF described in the previous question:\n",
    "\n",
    "a) How would you check if the number of latent topics you picked was appropriate? (2 pts)\n",
    "\n",
    "b) In the case of these nutritional values, why might NMF be more appropriate matrix factorization model than SVD? (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a)\n",
    "    Rerun the algo with different numbers of latent topics to see what the reconstruction error is and minimize and utilize the elbow method.\n",
    "\n",
    "    b)\n",
    "    We want our values to remain positive for iterpretability in the use of NMF, so in the case of nutritional values, negative numbers there would be hard to comprehend i.e. negative calories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
